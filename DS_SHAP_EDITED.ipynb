{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Av99bfTRVfQX"
      },
      "outputs": [],
      "source": [
        "!pip install pandas statsmodels scikit-learn shap kagglehub[pandas-datasets] -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import shap\n",
        "from itertools import combinations\n",
        "\n",
        "import warnings\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter"
      ],
      "metadata": {
        "id": "H_Ibrvr0bcri"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"KaggleV2-May-2016.csv\"\n",
        "path = kagglehub.dataset_download(\"joniarroba/noshowappointments\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "df = kagglehub.dataset_load(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"joniarroba/noshowappointments\",\n",
        "  file_path,\n",
        "  # pandas_kwargs={\"columns\": []}\n",
        "\n",
        ")\n",
        "\n",
        "df['No-show'] = df['No-show'].map({'Yes': 1, 'No': 0}) # 0 Assists, 1 No Assists\n",
        "df['Gender'] = df['Gender'].map({'M': 1, 'F': 0})\n",
        "df['Neighbourhood'], neighbourhood_map = pd.factorize(df['Neighbourhood'])\n",
        "neighbourhood_to_num = {name: i for i, name in enumerate(neighbourhood_map)}\n",
        "num_to_neighbourhood = dict(enumerate(neighbourhood_map))\n",
        "\n",
        "df.head()\n",
        "df = df.sample(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oMGJqXedaL2",
        "outputId": "a230af25-2a5e-42f6-b1db-d94999ea2049"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'noshowappointments' dataset.\n",
            "Path to dataset files: /kaggle/input/noshowappointments\n",
            "Using Colab cache for faster access to the 'noshowappointments' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "from itertools import combinations\n",
        "import pandas as pd\n",
        "import shap\n",
        "\n",
        "\n",
        "class DSExplainer:\n",
        "    def __init__(self, model, comb, X, Y, variant='absolute'):\n",
        "        \"\"\"\n",
        "        7 ACADEMICALLY JUSTIFIED VARIANTS:\n",
        "        'absolute'   : |SHAP| - Standard impact magnitude [SHAP]\n",
        "        'squared'    : SHAP² - Penalizes outliers [robust stats]\n",
        "        'signed'     : SHAP   - Causality direction\n",
        "        'normalized' : SHAP/sum - Relative proportion\n",
        "        'bootstrap'  : Bootstrap mean - Natural resampling\n",
        "        'bayes'      : Bayes factor - Bayesian evidence\n",
        "        'entropy'    : -SHAP*log|SHAP| - Mutual information\n",
        "        \"\"\"\n",
        "\n",
        "        self.model = model\n",
        "        self.comb = comb\n",
        "        self.variant = variant\n",
        "\n",
        "        X_processed = self.generate_combinations(X)\n",
        "        self.model.fit(X_processed, Y)\n",
        "        self.explainer = shap.TreeExplainer(self.model)\n",
        "        self.X_processed = X_processed\n",
        "\n",
        "\n",
        "    def getModel(self):\n",
        "        return self.model\n",
        "\n",
        "\n",
        "    def generate_combinations(self, X):\n",
        "        new_dataset = X.copy()\n",
        "        # Generate combinations of columns and add their sums to the dataset\n",
        "        for r in range(2, self.comb + 1):\n",
        "            for cols in combinations(X.columns, r):\n",
        "                new_col_name = \"_x_\".join(cols)\n",
        "                new_dataset[new_col_name] = X[list(cols)].sum(axis=1)\n",
        "\n",
        "        # Scale the dataset using MinMaxScaler\n",
        "        from sklearn.preprocessing import MinMaxScaler\n",
        "        scaler = MinMaxScaler()\n",
        "        new_dataset = pd.DataFrame(scaler.fit_transform(new_dataset),\n",
        "                                  columns=new_dataset.columns, index=X.index)\n",
        "        return new_dataset\n",
        "\n",
        "\n",
        "    def ds_values(self, X, n_boot=500, alpha=0.05):\n",
        "        X = self.generate_combinations(X)\n",
        "        shap_values = self.explainer.shap_values(X, check_additivity=False)\n",
        "        shap_values_df = pd.DataFrame(shap_values, columns=X.columns, index=X.index)\n",
        "\n",
        "        boot_masses = []\n",
        "        n_samples = len(X)\n",
        "\n",
        "        for i, row in shap_values_df.iterrows():\n",
        "            row_vals = row.values\n",
        "\n",
        "            if self.variant == 'absolute':\n",
        "                transformed = np.abs(row_vals)\n",
        "            elif self.variant == 'squared':\n",
        "                transformed = row_vals ** 2\n",
        "            elif self.variant == 'signed':\n",
        "                transformed = row_vals\n",
        "            elif self.variant == 'normalized':\n",
        "                transformed = row_vals / (np.sum(np.abs(row_vals)) + 1e-8)\n",
        "            elif self.variant == 'bootstrap':\n",
        "                transformed = self._bootstrap_mean(row_vals, n_boot // 10)\n",
        "            elif self.variant == 'bayes':\n",
        "                transformed = self._bayes_factor(row_vals, n_boot // 10)\n",
        "            elif self.variant == 'entropy':\n",
        "                transformed = -np.abs(row_vals) * np.log(np.abs(row_vals) + 1e-8)\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown variant: {self.variant}\")\n",
        "\n",
        "            orig_sum = np.sum(np.abs(transformed))\n",
        "\n",
        "            # Universal Bootstrap Confidence Interval\n",
        "            boot_diffs = []\n",
        "            for _ in range(n_boot):\n",
        "                boot_row = resample(transformed, random_state=np.random.randint(1000))\n",
        "                boot_shap = np.sum(np.abs(boot_row))\n",
        "                boot_diffs.append(orig_sum - boot_shap)\n",
        "\n",
        "            ci_low, ci_high = np.percentile(boot_diffs, [alpha/2*100, (1-alpha/2)*100])\n",
        "            ci_width = max(ci_high - ci_low, 1e-8)\n",
        "\n",
        "            feature_masses = {col: abs(row[col]) * ci_width / orig_sum\n",
        "                             for col in row.index}\n",
        "            boot_masses.append(feature_masses)\n",
        "\n",
        "        mass_df = pd.DataFrame(boot_masses, index=X.index)\n",
        "        mass_df = mass_df.div(mass_df.sum(axis=1), axis=0).fillna(0)\n",
        "\n",
        "        certainty_df, plausibility_df = self._compute_belief_plaus(mass_df)\n",
        "        return mass_df, certainty_df, plausibility_df\n",
        "\n",
        "\n",
        "    def _compute_belief_plaus(self, mass_df):\n",
        "        \"\"\"Strict Dempster-Shafer Theory: Valid Belief (Bel) and Plausibility (Pl)\"\"\"\n",
        "        results = []\n",
        "        feature_names = mass_df.columns.tolist()\n",
        "\n",
        "        for idx, row in mass_df.iterrows():\n",
        "            masses = row.to_dict()\n",
        "            certainty, plausibility = {}, {}\n",
        "\n",
        "            # Bel(A) = ∑ m(B) for B ⊆ A\n",
        "            for feat_name in feature_names:\n",
        "                hip = feat_name.split('_x_')\n",
        "                cert = sum(masses.get(h, 0) for h in hip if h in masses) + masses.get(feat_name, 0)\n",
        "                certainty[feat_name] = cert\n",
        "\n",
        "            # Pl(A) = ∑ m(B) for B ∩ A ≠ ∅\n",
        "            for feat_name in feature_names:\n",
        "                hip = feat_name.split('_x_')\n",
        "                plaus = sum(masses[hkey] for hkey, mass in masses.items()\n",
        "                            if any(h in hip for h in hkey.split('_x_')))\n",
        "                plausibility[feat_name] = min(1.0, plaus)  # ≤1 as required by DS theory\n",
        "\n",
        "            results.append({'Index': idx, 'Certainty': certainty, 'Plausibility': plausibility})\n",
        "\n",
        "        indices = [r['Index'] for r in results]\n",
        "        certainty_data = [[r['Certainty'].get(col, 0) for col in feature_names] for r in results]\n",
        "        plausibility_data = [[r['Plausibility'].get(col, 0) for col in feature_names] for r in results]\n",
        "\n",
        "        return (pd.DataFrame(certainty_data, columns=feature_names, index=indices),\n",
        "                pd.DataFrame(plausibility_data, columns=feature_names, index=indices))\n",
        "\n",
        "\n",
        "    def _bootstrap_mean(self, row_vals, n_boot):\n",
        "        \"\"\"Bootstrap mean - natural resampling (Efron, 1979)\"\"\"\n",
        "        boot_means = [np.mean(resample(row_vals)) for _ in range(n_boot)]\n",
        "        return np.abs(np.array(boot_means))\n",
        "\n",
        "\n",
        "    def _bayes_factor(self, row_vals, n_boot):\n",
        "        \"\"\"Bayes Factor - Bayesian evidence\"\"\"\n",
        "        # Simple approximation: BF01 = p(data|H0)/p(data|H1)\n",
        "        boot_liks = [np.sum(np.abs(resample(row_vals))) for _ in range(n_boot)]\n",
        "        bf01 = np.mean(boot_liks) / np.sum(np.abs(row_vals))\n",
        "        return np.abs(row_vals) * (1 / (1 + bf01))  # Bayesian scaling\n"
      ],
      "metadata": {
        "id": "MSJbSFfXWFLa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
        "\n",
        "data = df\n",
        "data = data.drop(columns=['PatientId', 'AppointmentID', 'ScheduledDay', 'AppointmentDay'])\n",
        "data = data.dropna()\n",
        "\n",
        "target_column = 'No-show'\n",
        "target = data[target_column]\n",
        "features = data.drop(columns=[target_column])\n",
        "\n",
        "numerical_columns = features.select_dtypes(include=['number']).columns\n",
        "categorical_columns = features.columns.difference(numerical_columns)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "features[numerical_columns] = scaler.fit_transform(features[numerical_columns])\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    features[col] = le.fit_transform(features[col]).astype(int)\n",
        "\n",
        "X = features\n",
        "y = target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "variants = ['absolute', 'squared', 'signed', 'normalized',\n",
        "           'bootstrap', 'bayes', 'entropy']\n",
        "\n",
        "results = {}\n",
        "max_comb = 3\n",
        "\n",
        "for variant in variants:\n",
        "    explainer = DSExplainer(model, comb=max_comb, X=X_train, Y=y_train, variant=variant)\n",
        "    mass, cert, plau = explainer.ds_values(X_test[:1])\n",
        "\n",
        "    results[variant] = {\n",
        "        'mass_top': mass.iloc[0].nlargest(3).to_dict(),\n",
        "        'plau_max': plau.iloc[0].max(),\n",
        "        'cert_max': cert.iloc[0].max()\n",
        "    }\n",
        "\n",
        "print(\"ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXSDanN5Vm7N",
        "outputId": "a0597f97-7dc9-4121-9ddb-ac770ed43548"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_variants_noshow_show(X_test, y_test, model, variants, max_combinations=3, top_n=3):\n",
        "    class_0_mask = y_test == 0  # Show = Row 0\n",
        "    class_1_mask = y_test == 1  # NoShow = Row 1\n",
        "\n",
        "    for variant in variants:\n",
        "        print(f\"\\n{'='*120}\")\n",
        "        print(f\"VARIANT: {variant.upper()} - NoShow(Row0) - Show(Row1)\")\n",
        "        print(f\"{'='*120}\")\n",
        "\n",
        "        # Single explainer per variant\n",
        "        explainer = DSExplainer(model, comb=max_combinations, X=X_train, Y=y_train, variant=variant)\n",
        "\n",
        "        # NoShow (Row 0) + Show (Row 1) = 2 rows total\n",
        "        X_noshow = X_test[class_0_mask][:1]\n",
        "        X_show = X_test[class_1_mask][:1]\n",
        "        X_combined = pd.concat([X_noshow, X_show]) if len(X_noshow)>0 and len(X_show)>0 else X_test[:2]\n",
        "\n",
        "        mass_df, certainty_df, plausibility_df = explainer.ds_values(X_combined)\n",
        "\n",
        "        # Format: Row 0=NoShow → Row 1=Show\n",
        "        parts = []\n",
        "        for i in range(min(2, len(mass_df))):\n",
        "            class_label = \"NOSHOW\" if i == 0 else \"SHOW\"\n",
        "            parts.append(format_top_row(mass_df, f\"mass_values_df ({class_label})\", i, top_n))\n",
        "            parts.append(format_top_row(certainty_df, f\"certainty_df ({class_label})\", i, top_n))\n",
        "            parts.append(format_top_row(plausibility_df, f\"plausibility_df ({class_label})\", i, top_n))\n",
        "\n",
        "        print(\"\\n\".join(parts))\n",
        "        print(\"-\"*120)\n",
        "\n",
        "\n",
        "# Original helper function (unchanged structure)\n",
        "top_n = 3\n",
        "def format_top_row(df, df_name, row_index, top_n):\n",
        "    row = df.iloc[row_index]\n",
        "    top_values = row.nlargest(top_n)\n",
        "    lines = [f\"\\n{df_name}, Row {row_index}:\"]\n",
        "    for col, val in top_values.items():\n",
        "        lines.append(f\"    {col}: {val}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "# Execute analysis\n",
        "analyze_variants_noshow_show(X_test, y_test, model, variants)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fsYU51CPW_D",
        "outputId": "5948ffeb-13c0-416d-bb92-5b45fa066d97"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================================================================================================\n",
            "VARIANT: ABSOLUTE - NoShow(Row0) - Show(Row1)\n",
            "========================================================================================================================\n",
            "\n",
            "mass_values_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.1930180765629768\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.07934976844022171\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.05249179093607704\n",
            "\n",
            "certainty_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.20561442386402537\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.09111117764808352\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.06427482618369446\n",
            "\n",
            "plausibility_df (NOSHOW), Row 0:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9971120712586268\n",
            "    Age_x_Neighbourhood_x_Handcap: 0.9970123806423467\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9969647943630231\n",
            "\n",
            "mass_values_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.07999501746355275\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.05334262543221199\n",
            "    Gender_x_Age: 0.04398224031715129\n",
            "\n",
            "certainty_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.09829417163578796\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.06675199433869933\n",
            "    Neighbourhood_x_Hipertension_x_SMS_received: 0.054708731867256485\n",
            "\n",
            "plausibility_df (SHOW), Row 1:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9784377023525934\n",
            "    Age_x_Neighbourhood_x_Scholarship: 0.9744397847295777\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9744143647173911\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "========================================================================================================================\n",
            "VARIANT: SQUARED - NoShow(Row0) - Show(Row1)\n",
            "========================================================================================================================\n",
            "\n",
            "mass_values_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.19301807656297656\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.07934976844022162\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.052491790936076976\n",
            "\n",
            "certainty_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.20561442386402515\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.09111117764808342\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.06427482618369439\n",
            "\n",
            "plausibility_df (NOSHOW), Row 0:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9971120712586257\n",
            "    Age_x_Neighbourhood_x_Handcap: 0.9970123806423457\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.996964794363022\n",
            "\n",
            "mass_values_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.07999501746355275\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.05334262543221197\n",
            "    Gender_x_Age: 0.04398224031715129\n",
            "\n",
            "certainty_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.09829417163578795\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.0667519943386993\n",
            "    Neighbourhood_x_Hipertension_x_SMS_received: 0.05470873186725647\n",
            "\n",
            "plausibility_df (SHOW), Row 1:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9784377023525931\n",
            "    Age_x_Neighbourhood_x_Scholarship: 0.9744397847295775\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9744143647173907\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "========================================================================================================================\n",
            "VARIANT: SIGNED - NoShow(Row0) - Show(Row1)\n",
            "========================================================================================================================\n",
            "\n",
            "mass_values_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.19301807656297687\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.07934976844022175\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.05249179093607706\n",
            "\n",
            "certainty_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.20561442386402545\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.09111117764808357\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.06427482618369448\n",
            "\n",
            "plausibility_df (NOSHOW), Row 0:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9971120712586272\n",
            "    Age_x_Neighbourhood_x_Handcap: 0.9970123806423472\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9969647943630237\n",
            "\n",
            "mass_values_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.07999501746355274\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.05334262543221197\n",
            "    Gender_x_Age: 0.04398224031715128\n",
            "\n",
            "certainty_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.09829417163578794\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.0667519943386993\n",
            "    Neighbourhood_x_Hipertension_x_SMS_received: 0.05470873186725647\n",
            "\n",
            "plausibility_df (SHOW), Row 1:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9784377023525931\n",
            "    Age_x_Neighbourhood_x_Scholarship: 0.9744397847295775\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9744143647173908\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "========================================================================================================================\n",
            "VARIANT: NORMALIZED - NoShow(Row0) - Show(Row1)\n",
            "========================================================================================================================\n",
            "\n",
            "mass_values_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.19301807656297668\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.07934976844022168\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.052491790936077004\n",
            "\n",
            "certainty_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.20561442386402526\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.09111117764808349\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.06427482618369441\n",
            "\n",
            "plausibility_df (NOSHOW), Row 0:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9971120712586262\n",
            "    Age_x_Neighbourhood_x_Handcap: 0.9970123806423462\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9969647943630225\n",
            "\n",
            "mass_values_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.07999501746355277\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.053342625432212\n",
            "    Gender_x_Age: 0.0439822403171513\n",
            "\n",
            "certainty_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.09829417163578796\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.06675199433869933\n",
            "    Neighbourhood_x_Hipertension_x_SMS_received: 0.054708731867256485\n",
            "\n",
            "plausibility_df (SHOW), Row 1:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9784377023525935\n",
            "    Age_x_Neighbourhood_x_Scholarship: 0.9744397847295778\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9744143647173912\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "========================================================================================================================\n",
            "VARIANT: BOOTSTRAP - NoShow(Row0) - Show(Row1)\n",
            "========================================================================================================================\n",
            "\n",
            "mass_values_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.19301807656297676\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.0793497684402217\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.052491790936077025\n",
            "\n",
            "certainty_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.20561442386402534\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.0911111776480835\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.06427482618369444\n",
            "\n",
            "plausibility_df (NOSHOW), Row 0:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9971120712586266\n",
            "    Age_x_Neighbourhood_x_Handcap: 0.9970123806423465\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9969647943630229\n",
            "\n",
            "mass_values_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.07999501746355275\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.05334262543221198\n",
            "    Gender_x_Age: 0.04398224031715129\n",
            "\n",
            "certainty_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.09829417163578795\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.06675199433869931\n",
            "    Neighbourhood_x_Hipertension_x_SMS_received: 0.05470873186725647\n",
            "\n",
            "plausibility_df (SHOW), Row 1:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9784377023525932\n",
            "    Age_x_Neighbourhood_x_Scholarship: 0.9744397847295775\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9744143647173908\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "========================================================================================================================\n",
            "VARIANT: BAYES - NoShow(Row0) - Show(Row1)\n",
            "========================================================================================================================\n",
            "\n",
            "mass_values_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.19301807656297684\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.07934976844022174\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.05249179093607704\n",
            "\n",
            "certainty_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.20561442386402543\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.09111117764808355\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.06427482618369446\n",
            "\n",
            "plausibility_df (NOSHOW), Row 0:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.997112071258627\n",
            "    Age_x_Neighbourhood_x_Handcap: 0.997012380642347\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9969647943630233\n",
            "\n",
            "mass_values_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.07999501746355277\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.053342625432212\n",
            "    Gender_x_Age: 0.043982240317151304\n",
            "\n",
            "certainty_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.09829417163578796\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.06675199433869933\n",
            "    Neighbourhood_x_Hipertension_x_SMS_received: 0.054708731867256485\n",
            "\n",
            "plausibility_df (SHOW), Row 1:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9784377023525934\n",
            "    Age_x_Neighbourhood_x_Scholarship: 0.9744397847295778\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9744143647173912\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "========================================================================================================================\n",
            "VARIANT: ENTROPY - NoShow(Row0) - Show(Row1)\n",
            "========================================================================================================================\n",
            "\n",
            "mass_values_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.1930180765629768\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.07934976844022172\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.05249179093607703\n",
            "\n",
            "certainty_df (NOSHOW), Row 0:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.20561442386402537\n",
            "    Neighbourhood_x_Scholarship_x_Hipertension: 0.09111117764808353\n",
            "    Gender_x_Neighbourhood_x_Scholarship: 0.06427482618369446\n",
            "\n",
            "plausibility_df (NOSHOW), Row 0:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9971120712586268\n",
            "    Age_x_Neighbourhood_x_Handcap: 0.9970123806423468\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9969647943630231\n",
            "\n",
            "mass_values_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.07999501746355271\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.05334262543221196\n",
            "    Gender_x_Age: 0.043982240317151276\n",
            "\n",
            "certainty_df (SHOW), Row 1:\n",
            "    Gender_x_Age_x_Neighbourhood: 0.09829417163578791\n",
            "    Gender_x_Neighbourhood_x_Hipertension: 0.06675199433869929\n",
            "    Neighbourhood_x_Hipertension_x_SMS_received: 0.05470873186725646\n",
            "\n",
            "plausibility_df (SHOW), Row 1:\n",
            "    Age_x_Neighbourhood_x_SMS_received: 0.9784377023525929\n",
            "    Age_x_Neighbourhood_x_Scholarship: 0.9744397847295773\n",
            "    Age_x_Neighbourhood_x_Hipertension: 0.9744143647173905\n",
            "------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://ollama.ai/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25IQWRZlRL8f",
        "outputId": "07163c28-f61d-4b66-e6a0-a3ef0b075491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 13281    0 13281    0     0  29218      0 --:--:-- --:--:-- --:--:-- 29189\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, time, requests\n",
        "\n",
        "ollama_proc = subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "# Espera breve y prueba\n",
        "time.sleep(3)\n",
        "print(\"Probing /api/tags...\")\n",
        "try:\n",
        "    print(requests.get(\"http://127.0.0.1:11434/api/tags\", timeout=5).json())\n",
        "except Exception as e:\n",
        "    print(\"Aún no responde:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am_RN4bCRMme",
        "outputId": "c00737bb-8264-441c-9081-6fd030413b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probing /api/tags...\n",
            "{'models': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json, time\n",
        "\n",
        "BASE = \"http://127.0.0.1:11434\"\n",
        "models = [\n",
        "  \"deepseek-r1:8b\",\n",
        "  \"mistral:7b\",\n",
        "  \"gemma3n:e4b\",\n",
        "  \"qwen3:8b\",\n",
        "  \"llama3.1:8b\",\n",
        "  \"gemma3:4b\"\n",
        "]\n",
        "\n",
        "for name in models:\n",
        "    r = requests.post(f\"{BASE}/api/pull\", json={\"model\": name}, stream=True, timeout=600)\n",
        "    # Leer el stream para que complete el pull\n",
        "    for line in r.iter_lines():\n",
        "        if line:\n",
        "            pass\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oUyw78mFRQ28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1= f\"De estos datos obtenidos de un analisis hecho con la teoría de demspter-shafer, sobre un dataset de gente que se le diagnostica alzheimer: {salida} que es lo que se puede concluir de esto\\n\\nDónde 0 es no tiene y 1 es que si tiene\"\n",
        "prompt2= \"Utiliza los siguientes parametros de evaluacion Precisión, Coherencia, Pertinencia y Claridad, da una calificacion del 0 al 1 por cada uno, solo dame la calificación\"\n",
        "prompt3= f\"Con respecto a esta pregunta '{prompt1}': \""
      ],
      "metadata": {
        "id": "HCRVepK3VpIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference vía API local\n",
        "def llamar_ollama(modelo, prompt):\n",
        "  resp = requests.post(\n",
        "      f\"{BASE}/v1/completions\",\n",
        "      json={\"model\": modelo,\"prompt\":prompt}\n",
        "  )\n",
        "\n",
        "  return resp.json()[\"choices\"][0][\"text\"]\n"
      ],
      "metadata": {
        "id": "-UcBFk7oaCz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "respuestas_citas = {}\n",
        "\n",
        "for name in models:\n",
        "  respuestas_citas[name] = llamar_ollama(name, prompt1)\n",
        "  print(f\"Respuesta de {name}, lista\")"
      ],
      "metadata": {
        "id": "hAVkjzZYnsNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analsis_respuestas = {}\n",
        "for name in models:\n",
        "    for modelo in models:\n",
        "        if name == modelo:\n",
        "            continue\n",
        "        analsis_respuestas.setdefault(name, {})\n",
        "        prompt = f\"{prompt2} {prompt3} {respuestas_citas[modelo]}\"\n",
        "        analsis_respuestas[name][modelo] = llamar_ollama(name, prompt)\n",
        "        print(f\"Respuesta de {name} contra {modelo}, lista\")"
      ],
      "metadata": {
        "id": "fOCqgQR9zqnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"{prompt2} {prompt3} {respuestas_citas[modelo]}\"\n",
        "print(llamar_ollama(\"llama3.1:8b\", prompt))"
      ],
      "metadata": {
        "id": "4hLTZBzYyK6B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}